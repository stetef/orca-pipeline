#!/bin/bash
#PBS -l nodes=1:ppn=1
#PBS -S /bin/bash
#PBS -N postproc-[BATCH_NAME]
#PBS -q workq
#PBS -V
#PBS -o postproc-[BATCH_NAME].sout
#PBS -e postproc-[BATCH_NAME].serr

set -euo pipefail

echo "[$(date -u +%Y-%m-%dT%H:%M:%SZ)] Postprocess start for [OUTPUT_ROOT]"
cd "[OUTPUT_ROOT]"

[EXTRACT_CMD]
[PROCESS_FEFF_CMD]
[PREPARE_DOWNLOAD_CMD]

echo "[$(date -u +%Y-%m-%dT%H:%M:%SZ)] Postprocess complete for [OUTPUT_ROOT]"
python - <<'PY'
import csv
from pathlib import Path

base = Path(r"[OUTPUT_ROOT]")
out_csv = base / 'pipeline-stage-times.csv'
rows = []
for run_dir in sorted(p for p in base.iterdir() if p.is_dir()):
    run_id = run_dir.name
    timings = {'run_id': run_id}
    for stage, suffix in [('orca', f'{run_id}-orca.timing'), ('corvus', f'{run_id}-corvus.timing')]:
        tpath = run_dir / suffix
        if not tpath.is_file():
            timings[f'{stage}_elapsed_seconds'] = ''
            timings[f'{stage}_exit_code'] = ''
            continue
        parsed = {}
        for raw in tpath.read_text(encoding='utf-8', errors='replace').splitlines():
            if '=' not in raw:
                continue
            key, value = raw.split('=', 1)
            parsed[key.strip()] = value.strip()
        timings[f'{stage}_elapsed_seconds'] = parsed.get('elapsed_seconds', '')
        timings[f'{stage}_exit_code'] = parsed.get('exit_code', '')
    rows.append(timings)

with out_csv.open('w', newline='', encoding='utf-8') as fh:
    writer = csv.DictWriter(
        fh,
        fieldnames=['run_id', 'orca_elapsed_seconds', 'orca_exit_code', 'corvus_elapsed_seconds', 'corvus_exit_code'],
    )
    writer.writeheader()
    writer.writerows(rows)

print(f'Wrote timing summary: {out_csv}')
PY
